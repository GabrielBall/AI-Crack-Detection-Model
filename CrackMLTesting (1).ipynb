{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Random ML Testing for crack detection\n",
        "\n"
      ],
      "metadata": {
        "id": "4XrWrl4CntaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset Loading TensorFlow"
      ],
      "metadata": {
        "id": "Fu2X-1gXu4qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "D3sjSnHxu4Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "archive = tf.keras.utils.get_file(origin=dataset_url, extract=True)\n",
        "data_dir = pathlib.Path(archive).with_suffix('')"
      ],
      "metadata": {
        "id": "M9VdS5AqvBdK",
        "outputId": "1810735b-caf6-4cb1-c287-372f327286e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228813984/228813984 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "metadata": {
        "id": "6Ur8y5LxvHRL",
        "outputId": "55cbb279-6e4f-4270-b00a-3990e14d4d88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset Loading PyTorch"
      ],
      "metadata": {
        "id": "mZNUM9wcq-6W"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jIGW-Fzq1CB"
      },
      "source": [
        "A custom Dataset class must implement three functions: `__init__`, `__len__`, and `__getitem__`.\n",
        "Take a look at this implementation; the FashionMNIST images are stored\n",
        "in a directory ``img_dir``, and their labels are stored separately in a CSV file ``annotations_file``.\n",
        "\n",
        "In the next sections, we'll break down what's happening in each of these functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoDHYDVtq1CB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kYG7mAqq1CB"
      },
      "source": [
        "### ``__init__``\n",
        "\n",
        "The __init__ function is run once when instantiating the Dataset object. We initialize\n",
        "the directory containing the images, the annotations file, and both transforms (covered\n",
        "in more detail in the next section).\n",
        "\n",
        "The labels.csv file looks like: ::\n",
        "\n",
        "    tshirt1.jpg, 0\n",
        "    tshirt2.jpg, 0\n",
        "    ......\n",
        "    ankleboot999.jpg, 9\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LC_op1Dq1CB"
      },
      "outputs": [],
      "source": [
        "def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "    self.img_labels = pd.read_csv(annotations_file)\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEVa_znwq1CB"
      },
      "source": [
        "### ``__len__``\n",
        "\n",
        "The __len__ function returns the number of samples in our dataset.\n",
        "\n",
        "Example:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_teh8Xreq1CC"
      },
      "outputs": [],
      "source": [
        "def __len__(self):\n",
        "    return len(self.img_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHiDMATKq1CC"
      },
      "source": [
        "### ``__getitem__``\n",
        "\n",
        "The __getitem__ function loads and returns a sample from the dataset at the given index ``idx``.\n",
        "Based on the index, it identifies the image's location on disk, converts that to a tensor using ``read_image``, retrieves the\n",
        "corresponding label from the csv data in ``self.img_labels``, calls the transform functions on them (if applicable), and returns the\n",
        "tensor image and corresponding label in a tuple.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UXQvQ2Zq1CC"
      },
      "outputs": [],
      "source": [
        "def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "    image = read_image(img_path)\n",
        "    label = self.img_labels.iloc[idx, 1]\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "        label = self.target_transform(label)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK4Kpw91q1CC"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AlexNet"
      ],
      "metadata": {
        "id": "ByhkMUCHnqg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wiO21tzn_Po",
        "outputId": "957570ba-7322-4e8a-cb28-57cc855fbecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8Pgi5KSmnpuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Personal Dataset"
      ],
      "metadata": {
        "id": "Qu2_Ut6Hj7m1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "raw_dataset = tf.data.TFRecordDataset(\"C:\\Users\\Gabriel\\Downloads\\crack.v2i.tfrecord.zip\\test\\concrete.tfrecord\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "phvZjQDuj-oi",
        "outputId": "97a411cd-f42f-4892-9430-1aa76e499a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-2-2d728f88aef1>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-2d728f88aef1>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    raw_dataset = tf.data.TFRecordDataset(\"C:\\Users\\Gabriel\\Downloads\\crack.v2i.tfrecord.zip\\test\\concrete.tfrecord\")\u001b[0m\n\u001b[0m                                                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WGt_SoLUj-PF"
      }
    }
  ]
}